{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from clean_data_for_decision_tree import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '../../data/labeled_csv_files'\n",
    "file = 'Anatel_labeled.csv'\n",
    "file_path = os.path.join(dir, file)\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rid_of_problematic_columns(df)\n",
    "rename_anatel_cols(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_null = (df.isnull().mean() * 100).round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative 1 - Getting rid of all missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_na = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original dataframe: 57328\n",
      "Lenght of non-nan dataframe: 55006\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of original dataframe: {len(df)}\")\n",
    "print(f\"Lenght of non-nan dataframe: {len(df_no_na)}\")\n",
    "\n",
    "df = df_no_na.copy()\n",
    "del df_no_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling/Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling and normalizing are not strictly necessary for decision trees. Here's why:\n",
    "\n",
    "**Decision trees are insensitive to monotonic transformations:**\n",
    "\n",
    "* Decision trees make splitting decisions based on the relative order of features, not their absolute values.\n",
    "* Scaling (e.g., MinMaxScaler) only changes the range of values, not their order.\n",
    "* Therefore, scaling doesn't affect how the tree splits the data.\n",
    "\n",
    "**However, there are some situations where scaling or normalizing might be beneficial:**\n",
    "\n",
    "* **Improves numerical stability:** Scaling features to a similar range can improve the numerical stability of the algorithm.\n",
    "* **Enhances visualization and interpretation:** Scaled features are easier to compare and interpret, especially when dealing with mixed units.\n",
    "* **Helps with comparing with other algorithms:** If you plan to combine decision trees with other algorithms that require scaled data, scaling beforehand can simplify the process.\n",
    "* **May improve performance in some cases:** Although not guaranteed, scaling can sometimes lead to slightly better performance for decision trees.\n",
    "\n",
    "**Normalization, however, requires caution:**\n",
    "\n",
    "* Normalization (e.g., StandardScaler) changes the distribution of features, which can affect the splitting decisions.\n",
    "* This may lead to suboptimal tree structures and potentially worse performance.\n",
    "\n",
    "**In summary:**\n",
    "\n",
    "* Scaling is generally not necessary for decision trees but can be beneficial in some situations.\n",
    "* Normalization should be used cautiously and with awareness of its potential impact.\n",
    "* It's recommended to experiment and compare performance with and without scaling/normalization in your specific case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset includes categorical variables, you'll need to encode them because decision trees typically work with numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Station': float64\n",
      "Column 'MinTxFreq': float64\n",
      "Column 'MaxTxFreq': float64\n",
      "Column 'MinRxFreq': float64\n",
      "Column 'MaxRxFreq': float64\n",
      "Column 'SiteType': object\n",
      "Column 'AntennaCode': int64\n",
      "Column 'AntennaGain': float64\n",
      "Column 'FrontBackAntennaRation': float64\n",
      "Column 'AnguloMeiaPotenciaAntena_max': float64\n",
      "Column 'ElevationAngle': float64\n",
      "Column 'Polarization': object\n",
      "Column 'AntennaHeight': float64\n",
      "Column 'TransmitterPower': float64\n",
      "Column 'NecessaryBandwidth': float64\n",
      "Column 'BasicFeatures': object\n",
      "Column 'LTE': bool\n",
      "Column 'WCDMA': bool\n",
      "Column 'GSM': bool\n",
      "Column 'NR_NSA': bool\n",
      "Column 'NR_SA-NSA': bool\n",
      "Column 'DMR': bool\n",
      "Column 'Digital': bool\n",
      "Column 'DaysSinceLicensing': float64\n",
      "Column 'DaysSinceFirstLicensing': float64\n",
      "Column 'DaysUntilExpiration': int64\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"Column '{col}': {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] SiglaUf_max\n",
    "- [x] CodMunicipio_max\n",
    "- [x] CodTipoClasseEstacao_max\n",
    "- [x] ClassInfraFisica_agg_non_none\n",
    "- [x] Polarizacao_max\n",
    "- [x] CodDebitoTFI_max\n",
    "- [x] CaracteristicasBasicas_agg_non_none\n",
    "- [x] LTE_max\n",
    "- [x] WCDMA_max\n",
    "- [x] GSM_max\n",
    "- [x] NR_NSA_max\n",
    "- [x] NR_SA-NSA_max\n",
    "- [x] DMR_max\n",
    "- [x] Digital_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Polarization'], prefix='Polarization')\n",
    "df = pd.get_dummies(df, columns=['BasicFeatures'], prefix='BasicFeatures')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees and random forests can handle boolean variables without encoding. They naturally make binary decisions based on the values of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dir, col, perc_null, file_path, file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Train the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Station', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
