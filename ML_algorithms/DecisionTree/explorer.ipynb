{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir = '../../data/labeled_csv_files'\n",
    "file = 'Anatel_labeled.csv'\n",
    "file_path = os.path.join(dir, file)\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_null = (df.isnull().mean() * 100).round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('CompartilhamentoInfraFisica_agg_non_none', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative 1 - Getting rid of all missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_na = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original dataframe: 57328\n",
      "Lenght of non-nan dataframe: 55006\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of original dataframe: {len(df)}\")\n",
    "print(f\"Lenght of non-nan dataframe: {len(df_no_na)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling/Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling and normalizing are not strictly necessary for decision trees. Here's why:\n",
    "\n",
    "**Decision trees are insensitive to monotonic transformations:**\n",
    "\n",
    "* Decision trees make splitting decisions based on the relative order of features, not their absolute values.\n",
    "* Scaling (e.g., MinMaxScaler) only changes the range of values, not their order.\n",
    "* Therefore, scaling doesn't affect how the tree splits the data.\n",
    "\n",
    "**However, there are some situations where scaling or normalizing might be beneficial:**\n",
    "\n",
    "* **Improves numerical stability:** Scaling features to a similar range can improve the numerical stability of the algorithm.\n",
    "* **Enhances visualization and interpretation:** Scaled features are easier to compare and interpret, especially when dealing with mixed units.\n",
    "* **Helps with comparing with other algorithms:** If you plan to combine decision trees with other algorithms that require scaled data, scaling beforehand can simplify the process.\n",
    "* **May improve performance in some cases:** Although not guaranteed, scaling can sometimes lead to slightly better performance for decision trees.\n",
    "\n",
    "**Normalization, however, requires caution:**\n",
    "\n",
    "* Normalization (e.g., StandardScaler) changes the distribution of features, which can affect the splitting decisions.\n",
    "* This may lead to suboptimal tree structures and potentially worse performance.\n",
    "\n",
    "**In summary:**\n",
    "\n",
    "* Scaling is generally not necessary for decision trees but can be beneficial in some situations.\n",
    "* Normalization should be used cautiously and with awareness of its potential impact.\n",
    "* It's recommended to experiment and compare performance with and without scaling/normalization in your specific case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset includes categorical variables, you'll need to encode them because decision trees typically work with numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'NumEstacao_': float64\n",
      "Column 'SiglaUf_max': object\n",
      "Column 'CodMunicipio_max': int64\n",
      "Column 'FreqTxMHz_min': float64\n",
      "Column 'FreqTxMHz_max': float64\n",
      "Column 'FreqRxMHz_min': float64\n",
      "Column 'FreqRxMHz_max': float64\n",
      "Column 'CodTipoClasseEstacao_max': object\n",
      "Column 'ClassInfraFisica_agg_non_none': object\n",
      "Column 'CodTipoAntena_max': int64\n",
      "Column 'GanhoAntena_agg_non_none': float64\n",
      "Column 'FrenteCostaAntena_max': float64\n",
      "Column 'AnguloMeiaPotenciaAntena_max': float64\n",
      "Column 'AnguloElevacao_min': float64\n",
      "Column 'Polarizacao_max': object\n",
      "Column 'AlturaAntena_max': float64\n",
      "Column 'PotenciaTransmissorWatts_max': float64\n",
      "Column 'CodDebitoTFI_max': object\n",
      "Column 'LarguraFaixaNecessaria_max': float64\n",
      "Column 'CaracteristicasBasicas_agg_non_none': object\n",
      "Column 'LTE_max': bool\n",
      "Column 'WCDMA_max': bool\n",
      "Column 'GSM_max': bool\n",
      "Column 'NR_NSA_max': bool\n",
      "Column 'NR_SA-NSA_max': bool\n",
      "Column 'DMR_max': bool\n",
      "Column 'Digital_max': bool\n",
      "Column 'DiasDesdeLicenciamento_max': float64\n",
      "Column 'DiasDesdePrimeiroLicenciamento_max': float64\n",
      "Column 'DiasAteExpirar_min': int64\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"Column '{col}': {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] SiglaUf_max\n",
    "- [x] CodMunicipio_max\n",
    "- [x] CodTipoClasseEstacao_max\n",
    "- [x] ClassInfraFisica_agg_non_none\n",
    "- [x] Polarizacao_max\n",
    "- [x] CodDebitoTFI_max\n",
    "- [x] CaracteristicasBasicas_agg_non_none\n",
    "- [x] LTE_max\n",
    "- [x] WCDMA_max\n",
    "- [x] GSM_max\n",
    "- [x] NR_NSA_max\n",
    "- [x] NR_SA-NSA_max\n",
    "- [x] DMR_max\n",
    "- [x] Digital_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CaracteristicasBasicas_agg_non_none\n",
       "G7W    51273\n",
       "G9W     4212\n",
       "D7W     1313\n",
       "D9W      300\n",
       "M7W      208\n",
       "0G9       14\n",
       "G7E        3\n",
       "0G7        2\n",
       "D7D        1\n",
       "7W         1\n",
       "F8W        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CaracteristicasBasicas_agg_non_none'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = pd.get_dummies(df, columns=['Polarizacao_max'], prefix='Polarizacao')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees and random forests can handle boolean variables without encoding. They naturally make binary decisions based on the values of the features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
