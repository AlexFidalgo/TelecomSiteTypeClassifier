{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decision_tree import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proportion of the dataset to include in the test split\n",
    "test_size = 0.2\n",
    "# Controls the shuffling applied to the data before applying the split (pass int for reproducible output across multiple function \n",
    "# calls)\n",
    "random_state = 42\n",
    "# The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “log_loss” and “entropy” \n",
    "# both for the Shannon information gain\n",
    "criterion = 'gini'\n",
    "# The maximum depth of the tree. i=If None, then nodes are expanded until all leaves are pure or until all leaves contain less than \n",
    "# min_samples_split samples\n",
    "max_depth = None\n",
    "# The minimum number of samples required to split an internal node\n",
    "min_samples_split = 2\n",
    "# The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at \n",
    "# least min_samples_leaf training samples in each of the left and right branches.\n",
    "min_samples_leaf = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anatel_file_path = '../../data/labeled_csv_files/Anatel_labeled.csv'\n",
    "\n",
    "anatel = pd.read_csv(anatel_file_path)\n",
    "\n",
    "# One-Hot Encoding\n",
    "anatel = pd.get_dummies(anatel, columns=['Polarization'], prefix='Polarization')\n",
    "anatel = pd.get_dummies(anatel, columns=['BasicFeatures'], prefix='BasicFeatures')\n",
    "# Decision trees and random forests can handle boolean variables without encoding. They naturally make binary decisions based on the values of the features.\n",
    "\n",
    "# Split data into features and target\n",
    "X = anatel.drop(\"SiteType\", axis=1)\n",
    "y = anatel[\"SiteType\"]\n",
    "\n",
    "# Split Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Build and Train the Decision Tree Model\n",
    "tree_model = DecisionTreeClassifier(random_state=random_state, criterion=criterion, max_depth=max_depth, \n",
    "                                    min_samples_split=min_samples_split,min_samples_leaf=min_samples_leaf)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to make predictions on the test set\n",
    "y_pred = tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cr = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = tree_model.feature_importances_\n",
    "print(\"Feature Importances:\\n\", feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(tree_model, X, y, cv=5)\n",
    "print(\"Cross-Validation Scores:\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(tree_model, param_grid, cv=5)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8143973822941284\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         COW       0.50      0.46      0.48        28\n",
      "    FASTSITE       0.33      0.33      0.33         3\n",
      "  GREENFIELD       0.89      0.89      0.89      8509\n",
      " HARMONIZADA       0.26      0.38      0.31        26\n",
      "      INDOOR       0.84      0.78      0.81       241\n",
      "     OUTDOOR       0.43      0.36      0.39        33\n",
      " RAN SHARING       0.77      0.80      0.78       298\n",
      "     ROOFTOP       0.49      0.49      0.49      1707\n",
      "   SMALLCELL       0.90      0.80      0.85        55\n",
      " STREETLEVEL       0.64      0.59      0.61       102\n",
      "\n",
      "    accuracy                           0.81     11002\n",
      "   macro avg       0.60      0.59      0.59     11002\n",
      "weighted avg       0.81      0.81      0.81     11002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "print(F\"Classification Report: \\n {cr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
